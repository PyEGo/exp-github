WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.
JAVA_HOME is not set
Traceback (most recent call last):
  File "test.py", line 4, in <module>
    df = ks.from_pandas(pdf)
  File "/koalas/databricks/koalas/namespace.py", line 123, in from_pandas
    return DataFrame(pobj)
  File "/koalas/databricks/koalas/frame.py", line 490, in __init__
    internal = InternalFrame.from_pandas(pdf)
  File "/koalas/databricks/koalas/internal.py", line 1095, in from_pandas
    sdf = default_session().createDataFrame(reset_index, schema=schema)
  File "/koalas/databricks/koalas/utils.py", line 436, in default_session
    session = builder.getOrCreate()
  File "/usr/local/lib/python3.8/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.8/site-packages/pyspark/context.py", line 384, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.8/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.8/site-packages/pyspark/context.py", line 331, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 108, in launch_gateway
    raise Exception("Java gateway process exited before sending its port number")
Exception: Java gateway process exited before sending its port number
